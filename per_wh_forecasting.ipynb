{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Material_ID</th>\n",
       "      <th>Item_ID</th>\n",
       "      <th>Warehouse_x</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Available_Time</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Danger_Type</th>\n",
       "      <th>Area</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Warehouse_ID_x</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>Warehouse_y</th>\n",
       "      <th>Distance(M)</th>\n",
       "      <th>Warehouse_ID_y</th>\n",
       "      <th>Destination_id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A140109</td>\n",
       "      <td>B-6128</td>\n",
       "      <td>P01-79c46a02-e12f-41c4-9ec9-25e48597ebfe</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>Blue Dart Hub - Siliguri</td>\n",
       "      <td>2022-04-05 23:59:59</td>\n",
       "      <td>2022-04-11 23:59:59</td>\n",
       "      <td>type_1</td>\n",
       "      <td>38880</td>\n",
       "      <td>30920000</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>WH_043</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>2444326</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A140109</td>\n",
       "      <td>B-6128</td>\n",
       "      <td>P01-43f08b0f-87f8-4a3f-91b8-40ed1947bdaa</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>Blue Dart Hub - Siliguri</td>\n",
       "      <td>2022-04-05 23:59:59</td>\n",
       "      <td>2022-04-11 23:59:59</td>\n",
       "      <td>type_1</td>\n",
       "      <td>38880</td>\n",
       "      <td>30920000</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>WH_043</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>2444326</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A140109</td>\n",
       "      <td>B-6128</td>\n",
       "      <td>P01-899d7387-aab0-4443-b6ba-7520fb4ee981</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>Blue Dart Hub - Siliguri</td>\n",
       "      <td>2022-04-05 23:59:59</td>\n",
       "      <td>2022-04-11 23:59:59</td>\n",
       "      <td>type_1</td>\n",
       "      <td>38880</td>\n",
       "      <td>30920000</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>WH_043</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>2444326</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A140109</td>\n",
       "      <td>B-6128</td>\n",
       "      <td>P01-acc23cdf-7fe7-4388-b8ff-5704eed86ef5</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>Blue Dart Hub - Siliguri</td>\n",
       "      <td>2022-04-05 23:59:59</td>\n",
       "      <td>2022-04-11 23:59:59</td>\n",
       "      <td>type_1</td>\n",
       "      <td>38880</td>\n",
       "      <td>30920000</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>WH_043</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>2444326</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A140109</td>\n",
       "      <td>B-6128</td>\n",
       "      <td>P01-cd0377d4-770c-45c3-9bd8-a5b098246e7e</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>Blue Dart Hub - Siliguri</td>\n",
       "      <td>2022-04-05 23:59:59</td>\n",
       "      <td>2022-04-11 23:59:59</td>\n",
       "      <td>type_1</td>\n",
       "      <td>38880</td>\n",
       "      <td>30920000</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>WH_043</td>\n",
       "      <td>Ecom Express - Rohtak</td>\n",
       "      <td>2444326</td>\n",
       "      <td>WH_001</td>\n",
       "      <td>0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order_ID Material_ID                                   Item_ID  \\\n",
       "0  A140109      B-6128  P01-79c46a02-e12f-41c4-9ec9-25e48597ebfe   \n",
       "1  A140109      B-6128  P01-43f08b0f-87f8-4a3f-91b8-40ed1947bdaa   \n",
       "2  A140109      B-6128  P01-899d7387-aab0-4443-b6ba-7520fb4ee981   \n",
       "3  A140109      B-6128  P01-acc23cdf-7fe7-4388-b8ff-5704eed86ef5   \n",
       "4  A140109      B-6128  P01-cd0377d4-770c-45c3-9bd8-a5b098246e7e   \n",
       "\n",
       "             Warehouse_x               Destination       Available_Time  \\\n",
       "0  Ecom Express - Rohtak  Blue Dart Hub - Siliguri  2022-04-05 23:59:59   \n",
       "1  Ecom Express - Rohtak  Blue Dart Hub - Siliguri  2022-04-05 23:59:59   \n",
       "2  Ecom Express - Rohtak  Blue Dart Hub - Siliguri  2022-04-05 23:59:59   \n",
       "3  Ecom Express - Rohtak  Blue Dart Hub - Siliguri  2022-04-05 23:59:59   \n",
       "4  Ecom Express - Rohtak  Blue Dart Hub - Siliguri  2022-04-05 23:59:59   \n",
       "\n",
       "              Deadline Danger_Type   Area    Weight Warehouse_ID_x  \\\n",
       "0  2022-04-11 23:59:59      type_1  38880  30920000         WH_001   \n",
       "1  2022-04-11 23:59:59      type_1  38880  30920000         WH_001   \n",
       "2  2022-04-11 23:59:59      type_1  38880  30920000         WH_001   \n",
       "3  2022-04-11 23:59:59      type_1  38880  30920000         WH_001   \n",
       "4  2022-04-11 23:59:59      type_1  38880  30920000         WH_001   \n",
       "\n",
       "  warehouse_id            Warehouse_y  Distance(M) Warehouse_ID_y  \\\n",
       "0       WH_043  Ecom Express - Rohtak      2444326         WH_001   \n",
       "1       WH_043  Ecom Express - Rohtak      2444326         WH_001   \n",
       "2       WH_043  Ecom Express - Rohtak      2444326         WH_001   \n",
       "3       WH_043  Ecom Express - Rohtak      2444326         WH_001   \n",
       "4       WH_043  Ecom Express - Rohtak      2444326         WH_001   \n",
       "\n",
       "   Destination_id    Category  Quantity  \n",
       "0               0  AUTOMOTIVE       197  \n",
       "1               0  AUTOMOTIVE        49  \n",
       "2               0  AUTOMOTIVE        38  \n",
       "3               0  AUTOMOTIVE        47  \n",
       "4               0  AUTOMOTIVE       191  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/zeal/Documents/6th sem/inv. mangmnt sy/chuimui/updated_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order_ID', 'Material_ID', 'Item_ID', 'Warehouse_x', 'Destination',\n",
       "       'Available_Time', 'Deadline', 'Danger_Type', 'Area', 'Weight',\n",
       "       'Warehouse_ID_x', 'warehouse_id', 'Warehouse_y', 'Distance(M)',\n",
       "       'Warehouse_ID_y', 'Destination_id', 'Category', 'Quantity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds                      Warehouse  \\\n",
      "0 2022-04-05 12:00:00            Amazon FC - Udaipur   \n",
      "1 2022-04-05 16:00:00            Amazon FC - Udaipur   \n",
      "2 2022-04-05 16:00:00  Delhivery Warehouse - Jodhpur   \n",
      "3 2022-04-05 19:00:00           Amazon FC - Amritsar   \n",
      "4 2022-04-05 19:00:00            Amazon FC - Dhanbad   \n",
      "\n",
      "                     Product    y  \n",
      "0  HOME AND KITCHEN I_C-0121  655  \n",
      "1  HOME AND KITCHEN I_C-0121  730  \n",
      "2              BEAUTY_E-0838  400  \n",
      "3        PET SUPPLIES_E-1251  543  \n",
      "4        BREAD/BAKERY_X-3286  146  \n"
     ]
    }
   ],
   "source": [
    "#  Preprocessing\n",
    "# Rename 'Destination' to 'Warehouse'\n",
    "df = df.rename(columns={'Destination': 'Warehouse'})\n",
    "\n",
    "# Drop 'Warehouse_x' column\n",
    "df = df.drop('Warehouse_x', axis=1)\n",
    "\n",
    "# Combine Category and Material_ID for more granularity.  Remove either if needed\n",
    "df['Product'] = df['Category'] + '_' + df['Material_ID']\n",
    "\n",
    "# Aggregate data to daily level\n",
    "df['Available_Time'] = pd.to_datetime(df['Available_Time'])\n",
    "daily_df = df.groupby(['Available_Time', 'Warehouse', 'Product'])['Quantity'].sum().reset_index()\n",
    "daily_df = daily_df.rename(columns={'Available_Time': 'ds', 'Quantity': 'y'}) # Prophet Requirements\n",
    "print(daily_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores: 20\n",
      "Forecasting Product: BREAD/BAKERY_X-3286, Warehouse: Amazon FC - Dhanbad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BREAD/BAKERY_X-3286, Warehouse: Amazon FC - Dhanbad\n",
      "Forecasting Product: AUTOMOTIVE_M-1129, Warehouse: Flipkart Hub - Bengaluru\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: AUTOMOTIVE_M-1129, Warehouse: Flipkart Hub - Bengaluru\n",
      "Forecasting Product: PET SUPPLIES_E-1251, Warehouse: Amazon FC - Amritsar\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: PLAYERS AND ELECTRONICS_X-2117, Warehouse: Amazon FC - Raipur\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: PLAYERS AND ELECTRONICS_X-2117, Warehouse: Amazon FC - Raipur\n",
      "Forecasting Product: DELI_X-6142, Warehouse: Amazon FC - Vijayawada\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: DELI_X-6142, Warehouse: Amazon FC - Vijayawada\n",
      "Forecasting Product: AUTOMOTIVE_B-6128, Warehouse: Blue Dart Hub - Siliguri\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: DELI_Y-3AHL, Warehouse: DTDC Hub - Bhavnagar\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: DELI_Y-3AHL, Warehouse: DTDC Hub - Bhavnagar\n",
      "Forecasting Product: SCHOOL AND OFFICE SUPPLIES_M-1127, Warehouse: Flipkart Hub - Bengaluru\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: SCHOOL AND OFFICE SUPPLIES_M-1127, Warehouse: Flipkart Hub - Bengaluru\n",
      "Forecasting Product: HOME AND KITCHEN II_Y-003L, Warehouse: DTDC Hub - Bhavnagar\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: HOME AND KITCHEN II_Y-003L, Warehouse: DTDC Hub - Bhavnagar\n",
      "Forecasting Product: PERSONAL CARE_Y-001L, Warehouse: DTDC Hub - Bhavnagar\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: HOME APPLIANCES_E-1044, Warehouse: Amazon FC - Ahmedabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: HOME APPLIANCES_E-1044, Warehouse: Amazon FC - Ahmedabad\n",
      "Forecasting Product: LADIESWEAR_E-0767, Warehouse: Amazon FC - Vijayawada\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: LAWN AND GARDEN_M-0835, Warehouse: Amazon FC - Bhubaneswar\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: CLEANING_E-1275, Warehouse: Amazon FC - Cuttack\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: CLEANING_E-1275, Warehouse: Amazon FC - Cuttack\n",
      "Forecasting Product: BOOKS_X-5603, Warehouse: Amazon FC - Ahmedabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BOOKS_X-5603, Warehouse: Amazon FC - Ahmedabad\n",
      "Forecasting Product: PET SUPPLIES_Y-004L, Warehouse: DTDC Hub - Bhavnagar\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: PLAYERS AND ELECTRONICS_C-0335, Warehouse: DTDC Hub - Mangalore\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: PRODUCE_C-0438, Warehouse: Amazon FC - Chandigarh\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: BABY CARE_M-1130, Warehouse: Flipkart Hub - Bengaluru\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BABY CARE_M-1130, Warehouse: Flipkart Hub - Bengaluru\n",
      "Forecasting Product: SEAFOOD_M-1128, Warehouse: Flipkart Hub - Bengaluru\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: SEAFOOD_M-1128, Warehouse: Flipkart Hub - Bengaluru\n",
      "Forecasting Product: CLEANING_X-5589, Warehouse: Amazon FC - Cuttack\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: CLEANING_X-5589, Warehouse: Amazon FC - Cuttack\n",
      "Forecasting Product: HARDWARE_Y-002L, Warehouse: DTDC Hub - Patna\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: PERSONAL CARE_E-1399, Warehouse: Amazon FC - Dhanbad\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: PERSONAL CARE_Y-001L, Warehouse: DTDC Hub - Patna\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: MEATS_E-1329, Warehouse: Amazon FC - Dhanbad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: MEATS_E-1329, Warehouse: Amazon FC - Dhanbad\n",
      "Forecast saved to forecasts/forecast_LAWN AND GARDEN-M-0835_Amazon-FC---Bhubaneswar.csv\n",
      "Forecasting Product: SEAFOOD_C-0518, Warehouse: DTDC Hub - PuneForecast saved to forecasts/forecast_LADIESWEAR-E-0767_Amazon-FC---Vijayawada.csv\n",
      "DataFrame shape: (3, 4)\n",
      "\n",
      "Forecasting Product: BREAD/BAKERY_M-0939, Warehouse: Delhivery Warehouse - Aurangabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BREAD/BAKERY_M-0939, Warehouse: Delhivery Warehouse - Aurangabad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting Product: CLEANING_M-0938, Warehouse: Delhivery Warehouse - Aurangabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: CLEANING_M-0938, Warehouse: Delhivery Warehouse - Aurangabad\n",
      "Forecasting Product: BEVERAGES_C-0327, Warehouse: Delhivery Warehouse - Belgaum\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: BOOKS_B-6298, Warehouse: Delhivery Warehouse - Nagpur\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: BEAUTY_E-0838, Warehouse: Delhivery Warehouse - Jodhpur\n",
      "DataFrame shape: (3, 4)\n",
      "Forecast saved to forecasts/forecast_PLAYERS AND ELECTRONICS-C-0335_DTDC-Hub---Mangalore.csv\n",
      "Forecasting Product: BREAD/BAKERY_B-6216, Warehouse: Delhivery Warehouse - Nagpur\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: POULTRY_F-001L, Warehouse: Ecom Express - Chennai\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: BEAUTY_E-0930, Warehouse: Ecom Express - Gorakhpur\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BEAUTY_E-0930, Warehouse: Ecom Express - Gorakhpur\n",
      "Forecast saved to forecasts/forecast_PRODUCE-C-0438_Amazon-FC---Chandigarh.csv\n",
      "Forecasting Product: DAIRY_X-6405, Warehouse: Amazon FC - Dhanbad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: DAIRY_X-6405, Warehouse: Amazon FC - Dhanbad\n",
      "Forecast saved to forecasts/forecast_HARDWARE-Y-002L_DTDC-Hub---Patna.csv\n",
      "Forecasting Product: LIQUOR,WINE,BEER_F-002L, Warehouse: Ecom Express - Indore\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: AUTOMOTIVE_A-0423, Warehouse: Ecom Express - Mysuru\n",
      "DataFrame shape: (3, 4)\n",
      "Forecast saved to forecasts/forecast_AUTOMOTIVE-B-6128_Blue-Dart-Hub---Siliguri.csv\n",
      "Forecasting Product: HOME AND KITCHEN I_S-0359, Warehouse: Ecom Express - Mysuru\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: BABY CARE_B-6155, Warehouse: Ecom Express - Thiruvananthapuram\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: PREPARED FOODS_C-0465, Warehouse: Amazon FC - Gwalior\n",
      "DataFrame shape: (3, 4)\n",
      "Forecast saved to forecasts/forecast_PET SUPPLIES-Y-004L_DTDC-Hub---Bhavnagar.csv\n",
      "Forecasting Product: PRODUCE_C-0438, Warehouse: Flipkart FC - Jaipur\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: HOME AND KITCHEN I_C-0121, Warehouse: Amazon FC - Udaipur\n",
      "DataFrame shape: (5, 4)\n",
      "Forecasting Product: HOME CARE_F-1AGL, Warehouse: Flipkart FC - Nellore\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: AUTOMOTIVE_C-0288, Warehouse: Flipkart FC - Ranchi\n",
      "DataFrame shape: (3, 4)\n",
      "Forecast saved to forecasts/forecast_PERSONAL CARE-Y-001L_DTDC-Hub---Patna.csvForecast saved to forecasts/forecast_BEAUTY-E-0838_Delhivery-Warehouse---Jodhpur.csv\n",
      "\n",
      "Forecasting Product: MAGAZINES_M-0545, Warehouse: Flipkart FC - Ranchi\n",
      "DataFrame shape: (3, 4)\n",
      "Forecast saved to forecasts/forecast_AUTOMOTIVE-A-0423_Ecom-Express---Mysuru.csv\n",
      "Forecast saved to forecasts/forecast_BABY CARE-B-6155_Ecom-Express---Thiruvananthapuram.csv\n",
      "Forecasting Product: GROCERY I_M-0361, Warehouse: Flipkart FC - Salem\n",
      "DataFrame shape: (3, 4)\n",
      "Forecasting Product: CLEANING_B-6349, Warehouse: Shadowfax Fulfillment - Dehradun\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: CLEANING_B-6349, Warehouse: Shadowfax Fulfillment - Dehradun\n",
      "Forecasting Product: HARDWARE_B-6422, Warehouse: Shadowfax Fulfillment - Noida\n",
      "DataFrame shape: (2, 4)\n",
      "Forecast saved to forecasts/forecast_PRODUCE-C-0438_Flipkart-FC---Jaipur.csv\n",
      "Forecasting Product: DELI_F-003L, Warehouse: Xpressbees Warehouse - Kochi\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: DELI_F-003L, Warehouse: Xpressbees Warehouse - Kochi\n",
      "Forecasting Product: CELEBRATION_Y-02CL, Warehouse: Xpressbees Warehouse - KolkataForecast saved to forecasts/forecast_BEVERAGES-C-0327_Delhivery-Warehouse---Belgaum.csv\n",
      "\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: LINGERIE_E-1515, Warehouse: Amazon FC - Vijayawada\n",
      "DataFrame shape: (6, 4)\n",
      "Forecast saved to forecasts/forecast_HOME AND KITCHEN I-S-0359_Ecom-Express---Mysuru.csv\n",
      "Forecast saved to forecasts/forecast_AUTOMOTIVE-C-0288_Flipkart-FC---Ranchi.csv\n",
      "Forecasting Product: HOME CARE_E-1116, Warehouse: Blue Dart Hub - Mumbai\n",
      "DataFrame shape: (5, 4)\n",
      "Forecasting Product: LADIESWEAR_M-0028, Warehouse: Blue Dart Hub - Varanasi\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: LADIESWEAR_M-0028, Warehouse: Blue Dart Hub - Varanasi\n",
      "Forecasting Product: GROCERY II_E-0088, Warehouse: DTDC Hub - Mangalore\n",
      "DataFrame shape: (6, 4)\n",
      "Forecasting Product: LIQUOR,WINE,BEER_E-1419, Warehouse: DTDC Hub - Nashik\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: LIQUOR,WINE,BEER_E-1419, Warehouse: DTDC Hub - Nashik\n",
      "Forecasting Product: DAIRY_E-1289, Warehouse: Xpressbees Warehouse - Kanpur\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: DAIRY_E-1289, Warehouse: Xpressbees Warehouse - Kanpur\n",
      "Forecast saved to forecasts/forecast_SEAFOOD-C-0518_DTDC-Hub---Pune.csv\n",
      "Forecasting Product: PLAYERS AND ELECTRONICS_M-1009, Warehouse: Amazon FC - Hyderabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: PLAYERS AND ELECTRONICS_M-1009, Warehouse: Amazon FC - Hyderabad\n",
      "Forecasting Product: BABY CARE_E-1328, Warehouse: Xpressbees Hub - Surat\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: PREPARED FOODS_M-1011, Warehouse: Amazon FC - Hyderabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: PREPARED FOODS_M-1011, Warehouse: Amazon FC - Hyderabad\n",
      "Forecasting Product: POULTRY_M-1010, Warehouse: Amazon FC - Hyderabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: POULTRY_M-1010, Warehouse: Amazon FC - Hyderabad\n",
      "Forecasting Product: PRODUCE_M-1012, Warehouse: Amazon FC - Hyderabad\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: PRODUCE_M-1012, Warehouse: Amazon FC - Hyderabad\n",
      "Forecasting Product: BABY CARE_X-7176, Warehouse: Amazon FC - Coimbatore\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BABY CARE_X-7176, Warehouse: Amazon FC - Coimbatore\n",
      "Forecasting Product: BOOKS_X-7078, Warehouse: Amazon FC - Coimbatore\n",
      "DataFrame shape: (2, 4)\n",
      "Forecasting Product: CELEBRATION_B-6243, Warehouse: Amazon FC - Coimbatore\n",
      "DataFrame shape: (2, 4)\n",
      "Forecast saved to forecasts/forecast_HOME CARE-F-1AGL_Flipkart-FC---Nellore.csv\n",
      "Forecasting Product: BEVERAGES_X-6671, Warehouse: Amazon FC - Guwahati\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BEVERAGES_X-6671, Warehouse: Amazon FC - Guwahati\n",
      "Forecasting Product: HOME APPLIANCES_C-0017, Warehouse: Amazon FC - Guwahati\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: HOME APPLIANCES_C-0017, Warehouse: Amazon FC - Guwahati\n",
      "Forecasting Product: MEATS_E-1522, Warehouse: Amazon FC - Guwahati\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: MEATS_E-1522, Warehouse: Amazon FC - Guwahati\n",
      "Forecasting Product: EGGS_E-0994, Warehouse: Amazon FC - Udaipur\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: EGGS_E-0994, Warehouse: Amazon FC - Udaipur\n",
      "Forecasting Product: PET SUPPLIES_X-6206, Warehouse: Amazon FC - Udaipur\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: PET SUPPLIES_X-6206, Warehouse: Amazon FC - Udaipur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:41:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting Product: BEVERAGES_C-0040, Warehouse: Amazon FC - Hubli\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: BEVERAGES_C-0040, Warehouse: Amazon FC - Hubli\n",
      "Forecast saved to forecasts/forecast_BOOKS-B-6298_Delhivery-Warehouse---Nagpur.csv\n",
      "Forecasting Product: HOME AND KITCHEN II_B-6257, Warehouse: Blue Dart Hub - Tiruchirappalli\n",
      "DataFrame shape: (1, 4)\n",
      "Not enough data (less than 2 rows) for Product: HOME AND KITCHEN II_B-6257, Warehouse: Blue Dart Hub - Tiruchirappalli\n",
      "Forecast saved to forecasts/forecast_GROCERY I-M-0361_Flipkart-FC---Salem.csv\n",
      "Forecast saved to forecasts/forecast_HOME AND KITCHEN I-C-0121_Amazon-FC---Udaipur.csv\n",
      "Forecast saved to forecasts/forecast_GROCERY II-E-0088_DTDC-Hub---Mangalore.csv\n",
      "Forecast saved to forecasts/forecast_LINGERIE-E-1515_Amazon-FC---Vijayawada.csv\n",
      "Forecast saved to forecasts/forecast_BOOKS-X-7078_Amazon-FC---Coimbatore.csv\n",
      "Forecast saved to forecasts/forecast_PET SUPPLIES-E-1251_Amazon-FC---Amritsar.csv\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'forecasts/forecast_BREAD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_97143/1594006062.py\", line 49, in forecast_product_warehouse\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/core/generic.py\", line 3967, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/io/formats/format.py\", line 1014, in to_csv\n    csv_formatter.save()\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py\", line 251, in save\n    with get_handle(\n         ^^^^^^^^^^^\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/io/common.py\", line 749, in get_handle\n    check_parent_directory(str(handle))\n  File \"/home/zeal/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/pandas/io/common.py\", line 616, in check_parent_directory\n    raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\nOSError: Cannot save file into a non-existent directory: 'forecasts/forecast_BREAD'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m num_cores \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available cores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast_product_warehouse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll forecasts complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/6th sem/inv. mangmnt sy/venv/lib/python3.11/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'forecasts/forecast_BREAD'"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "\n",
    "# Function to train Prophet model and forecast (to be parallelized)\n",
    "def forecast_product_warehouse(df, product, warehouse, periods=7):\n",
    "    \"\"\"\n",
    "    Trains a Prophet model for a specific product and warehouse,\n",
    "    and saves the forecast to a CSV file.\n",
    "    \"\"\"\n",
    "    product_warehouse_df = df[(df['Product'] == product) & (df['Warehouse'] == warehouse)].copy()\n",
    "\n",
    "    if product_warehouse_df.empty:\n",
    "        print(f\"No data for Product: {product}, Warehouse: {warehouse} - Empty DataFrame\")\n",
    "        return None\n",
    "\n",
    "    # Remove NaN values:\n",
    "    product_warehouse_df = product_warehouse_df.dropna()  # Drop rows with ANY NaN values\n",
    "    #Alternative is to fillna, if it makes sense for your data\n",
    "    #product_warehouse_df = product_warehouse_df.fillna(0)\n",
    "\n",
    "    print(f\"Forecasting Product: {product}, Warehouse: {warehouse}\")  # Debugging\n",
    "    print(f\"DataFrame shape: {product_warehouse_df.shape}\")  # Debugging\n",
    "\n",
    "    if len(product_warehouse_df) < 2:\n",
    "        print(f\"Not enough data (less than 2 rows) for Product: {product}, Warehouse: {warehouse}\")\n",
    "        return None\n",
    "\n",
    "    # Prophet model\n",
    "    try:  # Added a try-except block\n",
    "        model = Prophet()\n",
    "        model.fit(product_warehouse_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model for Product: {product}, Warehouse: {warehouse}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Make future dataframe\n",
    "    future = model.make_future_dataframe(periods=periods)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Select only the forecast period\n",
    "    forecast_7_days = forecast.tail(periods)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "    # Add product and warehouse info\n",
    "    forecast_7_days['Product'] = product\n",
    "    forecast_7_days['Warehouse'] = warehouse\n",
    "\n",
    "    # Save the forecast to a CSV file\n",
    "    filename = f\"forecasts/forecast_{product.replace('_', '-')}_{warehouse.replace(' ', '-')}.csv\" # Create more readable filenames\n",
    "    forecast_7_days.to_csv(filename, index=False)\n",
    "    print(f\"Forecast saved to {filename}\")\n",
    "\n",
    "    return None # No need to return the forecast\n",
    "\n",
    "# Create 'forecasts' directory if it doesn't exist\n",
    "if not os.path.exists('forecasts'):\n",
    "    os.makedirs('forecasts')\n",
    "\n",
    "# Get unique combinations of Product and Warehouse\n",
    "product_warehouse_combos = daily_df[['Product', 'Warehouse']].drop_duplicates()\n",
    "\n",
    "# Prepare arguments for parallel processing\n",
    "tasks = [\n",
    "    (daily_df, row['Product'], row['Warehouse'])\n",
    "    for index, row in product_warehouse_combos.iterrows()\n",
    "]\n",
    "\n",
    "# Run the forecasting in parallel\n",
    "# Adjust n_jobs based on your CPU cores. -1 means use all available cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of available cores: {num_cores}\")\n",
    "Parallel(n_jobs=num_cores)(delayed(forecast_product_warehouse)(*task) for task in tasks)\n",
    "\n",
    "print(\"All forecasts complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
